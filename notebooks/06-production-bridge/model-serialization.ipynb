{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serialization: PyTorch vs TensorFlow\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master model saving and loading in both frameworks\n",
    "- Compare serialization formats and best practices\n",
    "- Learn checkpoint management and versioning\n",
    "- Understand cross-platform compatibility considerations\n",
    "\n",
    "**Prerequisites:** Framework fundamentals, model training\n",
    "\n",
    "**Estimated Time:** 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join('..', '..', 'src'))\n",
    "\n",
    "from foundations.data_utils import get_tutorial_tabular_data\n",
    "from utils.comparison_tools import create_side_by_side_comparison\n",
    "\n",
    "# Try to import frameworks\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    PYTORCH_AVAILABLE = True\n",
    "    print(f\"âœ… PyTorch {torch.__version__} available\")\n",
    "except ImportError:\n",
    "    PYTORCH_AVAILABLE = False\n",
    "    print(\"âŒ PyTorch not available\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(f\"âœ… TensorFlow {tf.__version__} available\")\n",
    "except ImportError:\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "    print(\"âŒ TensorFlow not available\")\n",
    "\n",
    "# Create directories for saved models\n",
    "os.makedirs('../../models/pytorch', exist_ok=True)\n",
    "os.makedirs('../../models/tensorflow', exist_ok=True)\n",
    "os.makedirs('../../models/checkpoints', exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "if PYTORCH_AVAILABLE:\n",
    "    torch.manual_seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Model Saving and Loading\n",
    "\n",
    "Comparing the fundamental approaches to model serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BASIC MODEL SERIALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get sample data\n",
    "data = get_tutorial_tabular_data()\n",
    "X_train, X_test = data['X_train'], data['X_test']\n",
    "y_train, y_test = data['y_train'], data['y_test']\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "\n",
    "# PyTorch model saving\n",
    "if PYTORCH_AVAILABLE:\n",
    "    print(\"\\nðŸ”¥ PyTorch Model Serialization:\")\n",
    "    \n",
    "    class SimpleClassifier(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "            self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "            self.fc3 = nn.Linear(hidden_dim // 2, num_classes)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    \n",
    "    # Create and train model\n",
    "    pt_model = SimpleClassifier(input_dim, 64, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(pt_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Quick training\n",
    "    X_tensor = torch.FloatTensor(X_train)\n",
    "    y_tensor = torch.LongTensor(y_train)\n",
    "    \n",
    "    pt_model.train()\n",
    "    for epoch in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pt_model(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Final training loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Method 1: Save entire model\n",
    "    torch.save(pt_model, '../../models/pytorch/complete_model.pth')\n",
    "    print(\"âœ… Saved complete model\")\n",
    "    \n",
    "    # Method 2: Save state dict (recommended)\n",
    "    torch.save(pt_model.state_dict(), '../../models/pytorch/model_state_dict.pth')\n",
    "    print(\"âœ… Saved model state dict\")\n",
    "    \n",
    "    # Method 3: Save checkpoint with additional info\n",
    "    checkpoint = {\n",
    "        'model_state_dict': pt_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': 10,\n",
    "        'loss': loss.item(),\n",
    "        'model_config': {\n",
    "            'input_dim': input_dim,\n",
    "            'hidden_dim': 64,\n",
    "            'num_classes': num_classes\n",
    "        }\n",
    "    }\n",
    "    torch.save(checkpoint, '../../models/pytorch/checkpoint.pth')\n",
    "    print(\"âœ… Saved checkpoint with metadata\")\n",
    "    \n",
    "    # Test loading\n",
    "    print(\"\\nðŸ”„ Loading PyTorch models:\")\n",
    "    \n",
    "    # Load complete model\n",
    "    loaded_complete = torch.load('../../models/pytorch/complete_model.pth')\n",
    "    loaded_complete.eval()\n",
    "    \n",
    "    # Load state dict\n",
    "    loaded_state_dict = SimpleClassifier(input_dim, 64, num_classes)\n",
    "    loaded_state_dict.load_state_dict(torch.load('../../models/pytorch/model_state_dict.pth'))\n",
    "    loaded_state_dict.eval()\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint_loaded = torch.load('../../models/pytorch/checkpoint.pth')\n",
    "    loaded_checkpoint = SimpleClassifier(\n",
    "        checkpoint_loaded['model_config']['input_dim'],\n",
    "        checkpoint_loaded['model_config']['hidden_dim'],\n",
    "        checkpoint_loaded['model_config']['num_classes']\n",
    "    )\n",
    "    loaded_checkpoint.load_state_dict(checkpoint_loaded['model_state_dict'])\n",
    "    loaded_checkpoint.eval()\n",
    "    \n",
    "    # Verify models work\n",
    "    test_input = torch.FloatTensor(X_test[:5])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred1 = loaded_complete(test_input)\n",
    "        pred2 = loaded_state_dict(test_input)\n",
    "        pred3 = loaded_checkpoint(test_input)\n",
    "    \n",
    "    print(f\"Complete model predictions shape: {pred1.shape}\")\n",
    "    print(f\"State dict model predictions shape: {pred2.shape}\")\n",
    "    print(f\"Checkpoint model predictions shape: {pred3.shape}\")\n",
    "    print(f\"Predictions match: {torch.allclose(pred1, pred2) and torch.allclose(pred2, pred3)}\")\n",
    "\n",
    "# TensorFlow model saving\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"\\nðŸŸ  TensorFlow Model Serialization:\")\n",
    "    \n",
    "    # Create and train model\n",
    "    tf_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    tf_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Quick training\n",
    "    history = tf_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "    \n",
    "    # Method 1: SavedModel format (recommended)\n",
    "    tf_model.save('../../models/tensorflow/saved_model')\n",
    "    print(\"âœ… Saved in SavedModel format\")\n",
    "    \n",
    "    # Method 2: HDF5 format\n",
    "    tf_model.save('../../models/tensorflow/model.h5')\n",
    "    print(\"âœ… Saved in HDF5 format\")\n",
    "    \n",
    "    # Method 3: Save weights only\n",
    "    tf_model.save_weights('../../models/tensorflow/weights')\n",
    "    print(\"âœ… Saved weights only\")\n",
    "    \n",
    "    # Method 4: Save with custom metadata\n",
    "    model_metadata = {\n",
    "        'input_dim': input_dim,\n",
    "        'num_classes': num_classes,\n",
    "        'training_history': {\n",
    "            'final_loss': float(history.history['loss'][-1]),\n",
    "            'final_accuracy': float(history.history['accuracy'][-1]),\n",
    "            'epochs': len(history.history['loss'])\n",
    "        },\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open('../../models/tensorflow/metadata.json', 'w') as f:\n",
    "        json.dump(model_metadata, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… Saved metadata\")\n",
    "    \n",
    "    # Test loading\n",
    "    print(\"\\nðŸ”„ Loading TensorFlow models:\")\n",
    "    \n",
    "    # Load SavedModel\n",
    "    loaded_saved_model = tf.keras.models.load_model('../../models/tensorflow/saved_model')\n",
    "    \n",
    "    # Load HDF5\n",
    "    loaded_h5_model = tf.keras.models.load_model('../../models/tensorflow/model.h5')\n",
    "    \n",
    "    # Load weights only (need to recreate architecture)\n",
    "    loaded_weights_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    loaded_weights_model.load_weights('../../models/tensorflow/weights')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open('../../models/tensorflow/metadata.json', 'r') as f:\n",
    "        loaded_metadata = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded metadata: {loaded_metadata['training_history']}\")\n",
    "    \n",
    "    # Verify models work\n",
    "    test_input = X_test[:5]\n",
    "    \n",
    "    pred1 = loaded_saved_model.predict(test_input, verbose=0)\n",
    "    pred2 = loaded_h5_model.predict(test_input, verbose=0)\n",
    "    pred3 = loaded_weights_model.predict(test_input, verbose=0)\n",
    "    \n",
    "    print(f\"SavedModel predictions shape: {pred1.shape}\")\n",
    "    print(f\"HDF5 model predictions shape: {pred2.shape}\")\n",
    "    print(f\"Weights model predictions shape: {pred3.shape}\")\n",
    "    print(f\"Predictions match: {np.allclose(pred1, pred2) and np.allclose(pred2, pred3)}\")\n",
    "\n",
    "# Side-by-side comparison\n",
    "pytorch_save_code = \"\"\"\n",
    "import torch\n",
    "\n",
    "# Method 1: Save complete model (not recommended)\n",
    "torch.save(model, 'complete_model.pth')\n",
    "loaded_model = torch.load('complete_model.pth')\n",
    "\n",
    "# Method 2: Save state dict (recommended)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "model = MyModel()  # Need to recreate architecture\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "# Method 3: Save checkpoint with metadata\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': loss\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_save_code = \"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# Method 1: SavedModel format (recommended)\n",
    "model.save('my_model')  # Creates directory\n",
    "loaded_model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "# Method 2: HDF5 format\n",
    "model.save('model.h5')\n",
    "loaded_model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Method 3: Weights only\n",
    "model.save_weights('weights')\n",
    "new_model = create_model()  # Need to recreate architecture\n",
    "new_model.load_weights('weights')\n",
    "\n",
    "# Method 4: Custom checkpoint callback\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoint.h5', save_best_only=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(\n",
    "    pytorch_save_code, tensorflow_save_code, \"Model Saving Patterns\"\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 
 },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Versioning and Checkpoint Management\n",
    "\n",
    "Best practices for managing model versions and training checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL VERSIONING AND CHECKPOINTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyTorch checkpoint management\n",
    "if PYTORCH_AVAILABLE:\n",
    "    print(\"\\nðŸ”¥ PyTorch Checkpoint Management:\")\n",
    "    \n",
    "    class CheckpointManager:\n",
    "        def __init__(self, checkpoint_dir, max_checkpoints=5):\n",
    "            self.checkpoint_dir = checkpoint_dir\n",
    "            self.max_checkpoints = max_checkpoints\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        def save_checkpoint(self, model, optimizer, epoch, loss, metrics=None):\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'loss': loss,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metrics': metrics or {}\n",
    "            }\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                self.checkpoint_dir, f'checkpoint_epoch_{epoch:03d}.pth'\n",
    "            )\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            \n",
    "            # Clean up old checkpoints\n",
    "            self._cleanup_old_checkpoints()\n",
    "            \n",
    "            return checkpoint_path\n",
    "        \n",
    "        def load_latest_checkpoint(self, model, optimizer=None):\n",
    "            checkpoints = [f for f in os.listdir(self.checkpoint_dir) if f.endswith('.pth')]\n",
    "            if not checkpoints:\n",
    "                return None\n",
    "            \n",
    "            latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "            checkpoint_path = os.path.join(self.checkpoint_dir, latest_checkpoint)\n",
    "            \n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            if optimizer:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            \n",
    "            return checkpoint\n",
    "        \n",
    "        def _cleanup_old_checkpoints(self):\n",
    "            checkpoints = [f for f in os.listdir(self.checkpoint_dir) if f.endswith('.pth')]\n",
    "            if len(checkpoints) > self.max_checkpoints:\n",
    "                # Sort by epoch number\n",
    "                checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "                \n",
    "                # Remove oldest checkpoints\n",
    "                for checkpoint in checkpoints[:-self.max_checkpoints]:\n",
    "                    os.remove(os.path.join(self.checkpoint_dir, checkpoint))\n",
    "    \n",
    "    # Demonstrate checkpoint management\n",
    "    checkpoint_manager = CheckpointManager('../../models/checkpoints/pytorch')\n",
    "    \n",
    "    # Simulate training with checkpoints\n",
    "    model = SimpleClassifier(input_dim, 64, num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(1, 8):  # Save multiple checkpoints\n",
    "        # Simulate training\n",
    "        fake_loss = 1.0 / epoch  # Decreasing loss\n",
    "        fake_accuracy = min(0.95, 0.5 + epoch * 0.1)  # Increasing accuracy\n",
    "        \n",
    "        checkpoint_path = checkpoint_manager.save_checkpoint(\n",
    "            model, optimizer, epoch, fake_loss, \n",
    "            metrics={'accuracy': fake_accuracy}\n",
    "        )\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Saved checkpoint at epoch {epoch}: {os.path.basename(checkpoint_path)}\")\n",
    "    \n",
    "    # Load latest checkpoint\n",
    "    new_model = SimpleClassifier(input_dim, 64, num_classes)\n",
    "    new_optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n",
    "    \n",
    "    loaded_checkpoint = checkpoint_manager.load_latest_checkpoint(new_model, new_optimizer)\n",
    "    \n",
    "    if loaded_checkpoint:\n",
    "        print(f\"\\nâœ… Loaded checkpoint from epoch {loaded_checkpoint['epoch']}\")\n",
    "        print(f\"Loss: {loaded_checkpoint['loss']:.4f}\")\n",
    "        print(f\"Metrics: {loaded_checkpoint['metrics']}\")\n",
    "        print(f\"Timestamp: {loaded_checkpoint['timestamp']}\")\n",
    "\n",
    "# TensorFlow checkpoint management\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"\\nðŸŸ  TensorFlow Checkpoint Management:\")\n",
    "    \n",
    "    # Create model for checkpointing\n",
    "    tf_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    tf_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Method 1: ModelCheckpoint callback\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='../../models/checkpoints/tensorflow/checkpoint_{epoch:03d}.h5',\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "        period=2  # Save every 2 epochs\n",
    "    )\n",
    "    \n",
    "    # Method 2: Custom checkpoint callback\n",
    "    class CustomCheckpointCallback(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, checkpoint_dir, max_checkpoints=5):\n",
    "            self.checkpoint_dir = checkpoint_dir\n",
    "            self.max_checkpoints = max_checkpoints\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if epoch % 2 == 0:  # Save every 2 epochs\n",
    "                # Save model\n",
    "                model_path = os.path.join(\n",
    "                    self.checkpoint_dir, f'model_epoch_{epoch:03d}.h5'\n",
    "                )\n",
    "                self.model.save(model_path)\n",
    "                \n",
    "                # Save metadata\n",
    "                metadata = {\n",
    "                    'epoch': epoch,\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'metrics': logs or {}\n",
    "                }\n",
    "                \n",
    "                metadata_path = os.path.join(\n",
    "                    self.checkpoint_dir, f'metadata_epoch_{epoch:03d}.json'\n",
    "                )\n",
    "                \n",
    "                with open(metadata_path, 'w') as f:\n",
    "                    json.dump(metadata, f, indent=2)\n",
    "                \n",
    "                print(f\"\\nSaved checkpoint at epoch {epoch}\")\n",
    "                \n",
    "                # Cleanup old checkpoints\n",
    "                self._cleanup_old_checkpoints()\n",
    "        \n",
    "        def _cleanup_old_checkpoints(self):\n",
    "            model_files = [f for f in os.listdir(self.checkpoint_dir) if f.startswith('model_epoch_')]\n",
    "            if len(model_files) > self.max_checkpoints:\n",
    "                # Sort by epoch number\n",
    "                model_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "                \n",
    "                # Remove oldest files\n",
    "                for model_file in model_files[:-self.max_checkpoints]:\n",
    "                    epoch_num = model_file.split('_')[-1].split('.')[0]\n",
    "                    \n",
    "                    # Remove model and metadata files\n",
    "                    os.remove(os.path.join(self.checkpoint_dir, model_file))\n",
    "                    metadata_file = f'metadata_epoch_{epoch_num}.json'\n",
    "                    metadata_path = os.path.join(self.checkpoint_dir, metadata_file)\n",
    "                    if os.path.exists(metadata_path):\n",
    "                        os.remove(metadata_path)\n",
    "    \n",
    "    custom_checkpoint = CustomCheckpointCallback('../../models/checkpoints/tensorflow/custom')\n",
    "    \n",
    "    # Simulate training with checkpoints\n",
    "    print(\"Training with checkpoint callbacks...\")\n",
    "    \n",
    "    # Create dummy data for quick training\n",
    "    dummy_X = np.random.random((100, input_dim))\n",
    "    dummy_y = np.random.randint(0, num_classes, 100)\n",
    "    \n",
    "    history = tf_model.fit(\n",
    "        dummy_X, dummy_y,\n",
    "        epochs=7,\n",
    "        verbose=0,\n",
    "        callbacks=[custom_checkpoint]\n",
    "    )\n",
    "    \n",
    "    # Load latest checkpoint\n",
    "    checkpoint_dir = '../../models/checkpoints/tensorflow/custom'\n",
    "    model_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('model_epoch_')]\n",
    "    \n",
    "    if model_files:\n",
    "        latest_model_file = max(model_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "        latest_model_path = os.path.join(checkpoint_dir, latest_model_file)\n",
    "        \n",
    "        loaded_model = tf.keras.models.load_model(latest_model_path)\n",
    "        \n",
    "        # Load corresponding metadata\n",
    "        epoch_num = latest_model_file.split('_')[-1].split('.')[0]\n",
    "        metadata_path = os.path.join(checkpoint_dir, f'metadata_epoch_{epoch_num}.json')\n",
    "        \n",
    "        if os.path.exists(metadata_path):\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            print(f\"\\nâœ… Loaded latest checkpoint from epoch {metadata['epoch']}\")\n",
    "            print(f\"Metrics: {metadata['metrics']}\")\n",
    "            print(f\"Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Checkpoint Management Best Practices:\")\n",
    "print(\"â€¢ Save checkpoints periodically during training\")\n",
    "print(\"â€¢ Include metadata (epoch, metrics, timestamp)\")\n",
    "print(\"â€¢ Implement cleanup to avoid disk space issues\")\n",
    "print(\"â€¢ Save best model separately from regular checkpoints\")\n",
    "print(\"â€¢ Use consistent naming conventions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Platform Compatibility\n",
    "\n",
    "Ensuring models work across different environments and platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CROSS-PLATFORM COMPATIBILITY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyTorch compatibility considerations\n",
    "if PYTORCH_AVAILABLE:\n",
    "    print(\"\\nðŸ”¥ PyTorch Cross-Platform Considerations:\")\n",
    "    \n",
    "    # Check device compatibility\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Current device: {device}\")\n",
    "    \n",
    "    # Create model on specific device\n",
    "    model = SimpleClassifier(input_dim, 64, num_classes).to(device)\n",
    "    \n",
    "    # Save with device-agnostic approach\n",
    "    def save_model_portable(model, path):\n",
    "        \"\"\"Save model in a device-agnostic way\"\"\"\n",
    "        # Move to CPU before saving\n",
    "        model_cpu = model.cpu()\n",
    "        torch.save(model_cpu.state_dict(), path)\n",
    "        # Move back to original device\n",
    "        model.to(device)\n",
    "        return path\n",
    "    \n",
    "    def load_model_portable(model_class, path, device=None):\n",
    "        \"\"\"Load model with device flexibility\"\"\"\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load state dict with map_location\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        \n",
    "        # Create model and load weights\n",
    "        model = model_class().to(device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # Demonstrate portable saving/loading\n",
    "    portable_path = '../../models/pytorch/portable_model.pth'\n",
    "    save_model_portable(model, portable_path)\n",
    "    \n",
    "    # Load on different device (simulate)\n",
    "    loaded_model = load_model_portable(\n",
    "        lambda: SimpleClassifier(input_dim, 64, num_classes),\n",
    "        portable_path,\n",
    "        device=torch.device('cpu')  # Force CPU\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Model loaded on: {next(loaded_model.parameters()).device}\")\n",
    "    \n",
    "    # Version compatibility info\n",
    "    version_info = {\n",
    "        'pytorch_version': torch.__version__,\n",
    "        'python_version': sys.version,\n",
    "        'platform': sys.platform,\n",
    "        'cuda_available': torch.cuda.is_available()\n",
    "    }\n",
    "    \n",
    "    with open('../../models/pytorch/version_info.json', 'w') as f:\n",
    "        json.dump(version_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved version info: PyTorch {torch.__version__}\")\n",
    "\n",
    "# TensorFlow compatibility considerations\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"\\nðŸŸ  TensorFlow Cross-Platform Considerations:\")\n",
    "    \n",
    "    # Create model\n",
    "    tf_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    tf_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Quick training\n",
    "    tf_model.fit(X_train[:100], y_train[:100], epochs=3, verbose=0)\n",
    "    \n",
    "    # Save in different formats for compatibility\n",
    "    \n",
    "    # 1. SavedModel (most compatible)\n",
    "    tf_model.save('../../models/tensorflow/compatible_savedmodel')\n",
    "    print(\"âœ… Saved in SavedModel format (most compatible)\")\n",
    "    \n",
    "    # 2. TensorFlow Lite (mobile/edge deployment)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    with open('../../models/tensorflow/model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(\"âœ… Saved TensorFlow Lite model\")\n",
    "    \n",
    "    # 3. TensorFlow.js (web deployment)\n",
    "    try:\n",
    "        import tensorflowjs as tfjs\n",
    "        tfjs.converters.save_keras_model(tf_model, '../../models/tensorflow/tfjs_model')\n",
    "        print(\"âœ… Saved TensorFlow.js model\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ TensorFlow.js not available (install with: pip install tensorflowjs)\")\n",
    "    \n",
    "    # Version and environment info\n",
    "    tf_version_info = {\n",
    "        'tensorflow_version': tf.__version__,\n",
    "        'python_version': sys.version,\n",
    "        'platform': sys.platform,\n",
    "        'gpu_available': len(tf.config.list_physical_devices('GPU')) > 0,\n",
    "        'model_input_shape': tf_model.input_shape,\n",
    "        'model_output_shape': tf_model.output_shape\n",
    "    }\n",
    "    \n",
    "    with open('../../models/tensorflow/tf_version_info.json', 'w') as f:\n",
    "        json.dump(tf_version_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved version info: TensorFlow {tf.__version__}\")\n",
    "    \n",
    "    # Test TensorFlow Lite model\n",
    "    interpreter = tf.lite.Interpreter(model_path='../../models/tensorflow/model.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Test inference\n",
    "    test_input = X_test[:1].astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    keras_output = tf_model.predict(test_input, verbose=0)\n",
    "    \n",
    "    print(f\"\\nðŸ“± TensorFlow Lite compatibility:\")\n",
    "    print(f\"Original model output shape: {keras_output.shape}\")\n",
    "    print(f\"TFLite model output shape: {tflite_output.shape}\")\n",
    "    print(f\"Outputs match: {np.allclose(keras_output, tflite_output, atol=1e-5)}\")\n",
    "\n",
    "# Cross-framework compatibility tips\n",
    "print(\"\\nðŸ”„ Cross-Framework Compatibility Tips:\")\n",
    "\n",
    "compatibility_tips = {\n",
    "    'PyTorch': [\n",
    "        \"Use map_location when loading models\",\n",
    "        \"Save models on CPU for device independence\",\n",
    "        \"Include model architecture in checkpoints\",\n",
    "        \"Use ONNX for cross-framework compatibility\",\n",
    "        \"Save version information with models\"\n",
    "    ],\n",
    "    'TensorFlow': [\n",
    "        \"Prefer SavedModel format for production\",\n",
    "        \"Use TensorFlow Lite for mobile deployment\",\n",
    "        \"Consider TensorFlow.js for web deployment\",\n",
    "        \"Include input/output shapes in metadata\",\n",
    "        \"Test models across TensorFlow versions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for framework, tips in compatibility_tips.items():\n",
    "    print(f\"\\n{framework}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"  â€¢ {tip}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Takeaways:\")\n",
    "print(\"â€¢ Always save version and environment information\")\n",
    "print(\"â€¢ Test model loading in different environments\")\n",
    "print(\"â€¢ Use framework-specific best practices for serialization\")\n",
    "print(\"â€¢ Consider deployment target when choosing save format\")\n",
    "print(\"â€¢ Implement proper error handling for model loading\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
