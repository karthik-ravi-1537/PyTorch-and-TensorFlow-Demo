{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and Operations: PyTorch vs TensorFlow\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master tensor creation, manipulation, and operations in both frameworks\n",
    "- Understand device management (CPU/GPU) differences\n",
    "- Compare performance and memory usage patterns\n",
    "- Learn when to choose each framework for tensor operations\n",
    "\n",
    "**Prerequisites:** NumPy essentials, data preparation basics\n",
    "\n",
    "**Estimated Time:** 45 minutes\n",
    "\n",
    "---\n",
    "\n",
    "Tensors are the fundamental data structure in both PyTorch and TensorFlow. Understanding how each framework handles tensors is crucial for:\n",
    "- Efficient model implementation\n",
    "- Memory management\n",
    "- Performance optimization\n",
    "- Debugging and development\n",
    "\n",
    "This notebook provides side-by-side comparisons to help you understand the similarities and differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path for our utilities\n",
    "sys.path.append(os.path.join('..', '..', 'src'))\n",
    "\n",
    "# Import our comparison utilities\n",
    "from utils.comparison_tools import FrameworkComparison, create_side_by_side_comparison\n",
    "from utils.visualization import FrameworkVisualizer\n",
    "\n",
    "# Try to import frameworks\n",
    "try:\n",
    "    import torch\n",
    "    PYTORCH_AVAILABLE = True\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} available\")\n",
    "\n",
    "    # Check for GPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   üöÄ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"   üíª CPU only\")\n",
    "\n",
    "except ImportError:\n",
    "    PYTORCH_AVAILABLE = False\n",
    "    print(\"‚ùå PyTorch not available\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(f\"‚úÖ TensorFlow {tf.__version__} available\")\n",
    "\n",
    "    # Check for GPU\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"   üöÄ GPU available: {len(tf.config.list_physical_devices('GPU'))} device(s)\")\n",
    "    else:\n",
    "        print(\"   üíª CPU only\")\n",
    "\n",
    "except ImportError:\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "    print(\"‚ùå TensorFlow not available\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "if PYTORCH_AVAILABLE:\n",
    "    torch.manual_seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "print(f\"\\nNumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Creation\n",
    "\n",
    "Understanding different ways to create tensors in both frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TENSOR CREATION COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison framework\n",
    "comparator = FrameworkComparison()\n",
    "\n",
    "# Example 1: Creating tensors from lists\n",
    "print(\"\\n1. Creating tensors from lists:\")\n",
    "\n",
    "data_list = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "def create_pytorch_from_list():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        return torch.tensor(data_list, dtype=torch.float32)\n",
    "    return None\n",
    "\n",
    "def create_tensorflow_from_list():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        return tf.constant(data_list, dtype=tf.float32)\n",
    "    return None\n",
    "\n",
    "result = comparator.compare_implementations(\n",
    "    pytorch_func=create_pytorch_from_list,\n",
    "    tensorflow_func=create_tensorflow_from_list,\n",
    "    name=\"tensor_from_list\"\n",
    ")\n",
    "\n",
    "if result['pytorch']['success'] and result['tensorflow']['success']:\n",
    "    pt_tensor = result['pytorch']['output']\n",
    "    tf_tensor = result['tensorflow']['output']\n",
    "\n",
    "    print(f\"PyTorch: {pt_tensor.shape}, dtype: {pt_tensor.dtype}\")\n",
    "    print(f\"TensorFlow: {tf_tensor.shape}, dtype: {tf_tensor.dtype}\")\n",
    "    print(f\"Values match: {result['comparison']['outputs_equal']}\")\n",
    "\n",
    "# Show side-by-side code\n",
    "pytorch_code = \"\"\"\n",
    "import torch\n",
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "tensor = torch.tensor(data, dtype=torch.float32)\n",
    "print(f\"Shape: {tensor.shape}\")\n",
    "print(f\"Dtype: {tensor.dtype}\")\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_code = \"\"\"\n",
    "import tensorflow as tf\n",
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "tensor = tf.constant(data, dtype=tf.float32)\n",
    "print(f\"Shape: {tensor.shape}\")\n",
    "print(f\"Dtype: {tensor.dtype}\")\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(pytorch_code, tensorflow_code, \"Creating Tensors from Lists\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Creating special tensors (zeros, ones, random)\n",
    "print(\"\\n2. Creating special tensors:\")\n",
    "\n",
    "shape = (3, 4)\n",
    "\n",
    "# Zeros\n",
    "def create_pytorch_zeros():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        return torch.zeros(shape, dtype=torch.float32)\n",
    "    return None\n",
    "\n",
    "def create_tensorflow_zeros():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        return tf.zeros(shape, dtype=tf.float32)\n",
    "    return None\n",
    "\n",
    "zeros_result = comparator.compare_implementations(\n",
    "    pytorch_func=create_pytorch_zeros,\n",
    "    tensorflow_func=create_tensorflow_zeros,\n",
    "    name=\"zeros_tensor\"\n",
    ")\n",
    "\n",
    "print(f\"Zeros tensor comparison: {zeros_result['comparison'].get('outputs_equal', 'N/A')}\")\n",
    "\n",
    "# Random tensors\n",
    "def create_pytorch_random():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        torch.manual_seed(42)  # For reproducibility\n",
    "        return torch.randn(shape, dtype=torch.float32)\n",
    "    return None\n",
    "\n",
    "def create_tensorflow_random():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        tf.random.set_seed(42)  # For reproducibility\n",
    "        return tf.random.normal(shape, dtype=tf.float32)\n",
    "    return None\n",
    "\n",
    "random_result = comparator.compare_implementations(\n",
    "    pytorch_func=create_pytorch_random,\n",
    "    tensorflow_func=create_tensorflow_random,\n",
    "    name=\"random_tensor\"\n",
    ")\n",
    "\n",
    "print(f\"Random tensor shapes match: {random_result['comparison'].get('shape_match', 'N/A')}\")\n",
    "print(f\"Random values are different (expected): {not random_result['comparison'].get('outputs_equal', True)}\")\n",
    "\n",
    "# Show comprehensive tensor creation methods\n",
    "print(\"\\nüìã Tensor Creation Methods Comparison:\")\n",
    "creation_methods = {\n",
    "    \"From data\": {\n",
    "        \"PyTorch\": \"torch.tensor(data)\",\n",
    "        \"TensorFlow\": \"tf.constant(data)\"\n",
    "    },\n",
    "    \"Zeros\": {\n",
    "        \"PyTorch\": \"torch.zeros(shape)\",\n",
    "        \"TensorFlow\": \"tf.zeros(shape)\"\n",
    "    },\n",
    "    \"Ones\": {\n",
    "        \"PyTorch\": \"torch.ones(shape)\",\n",
    "        \"TensorFlow\": \"tf.ones(shape)\"\n",
    "    },\n",
    "    \"Random normal\": {\n",
    "        \"PyTorch\": \"torch.randn(shape)\",\n",
    "        \"TensorFlow\": \"tf.random.normal(shape)\"\n",
    "    },\n",
    "    \"Random uniform\": {\n",
    "        \"PyTorch\": \"torch.rand(shape)\",\n",
    "        \"TensorFlow\": \"tf.random.uniform(shape)\"\n",
    "    },\n",
    "    \"Identity\": {\n",
    "        \"PyTorch\": \"torch.eye(n)\",\n",
    "        \"TensorFlow\": \"tf.eye(n)\"\n",
    "    },\n",
    "    \"Range\": {\n",
    "        \"PyTorch\": \"torch.arange(start, end)\",\n",
    "        \"TensorFlow\": \"tf.range(start, limit)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for method, frameworks in creation_methods.items():\n",
    "    print(f\"{method:15} | PyTorch: {frameworks['PyTorch']:25} | TensorFlow: {frameworks['TensorFlow']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Tensor Operations\n",
    "\n",
    "Comparing fundamental tensor operations between frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASIC TENSOR OPERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample tensors for operations\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.randn(3, 4).astype(np.float32)\n",
    "\n",
    "if PYTORCH_AVAILABLE:\n",
    "    pt_tensor = torch.from_numpy(sample_data)\n",
    "    print(f\"PyTorch tensor: {pt_tensor.shape}, dtype: {pt_tensor.dtype}\")\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf_tensor = tf.constant(sample_data)\n",
    "    print(f\"TensorFlow tensor: {tf_tensor.shape}, dtype: {tf_tensor.dtype}\")\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"\\n1. Element-wise Operations:\")\n",
    "\n",
    "def pytorch_elementwise_ops():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        x = torch.from_numpy(sample_data)\n",
    "\n",
    "        # Basic operations\n",
    "        squared = x ** 2\n",
    "        sqrt_abs = torch.sqrt(torch.abs(x))\n",
    "        exp_x = torch.exp(x)\n",
    "\n",
    "        # Activation functions\n",
    "        relu = torch.relu(x)\n",
    "        sigmoid = torch.sigmoid(x)\n",
    "        tanh = torch.tanh(x)\n",
    "\n",
    "        return {\n",
    "            'squared_mean': torch.mean(squared).item(),\n",
    "            'sqrt_abs_mean': torch.mean(sqrt_abs).item(),\n",
    "            'exp_mean': torch.mean(exp_x).item(),\n",
    "            'relu_mean': torch.mean(relu).item(),\n",
    "            'sigmoid_mean': torch.mean(sigmoid).item(),\n",
    "            'tanh_mean': torch.mean(tanh).item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_elementwise_ops():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        x = tf.constant(sample_data)\n",
    "\n",
    "        # Basic operations\n",
    "        squared = tf.square(x)\n",
    "        sqrt_abs = tf.sqrt(tf.abs(x))\n",
    "        exp_x = tf.exp(x)\n",
    "\n",
    "        # Activation functions\n",
    "        relu = tf.nn.relu(x)\n",
    "        sigmoid = tf.nn.sigmoid(x)\n",
    "        tanh = tf.nn.tanh(x)\n",
    "\n",
    "        return {\n",
    "            'squared_mean': tf.reduce_mean(squared).numpy().item(),\n",
    "            'sqrt_abs_mean': tf.reduce_mean(sqrt_abs).numpy().item(),\n",
    "            'exp_mean': tf.reduce_mean(exp_x).numpy().item(),\n",
    "            'relu_mean': tf.reduce_mean(relu).numpy().item(),\n",
    "            'sigmoid_mean': tf.reduce_mean(sigmoid).numpy().item(),\n",
    "            'tanh_mean': tf.reduce_mean(tanh).numpy().item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "ops_result = comparator.compare_implementations(\n",
    "    pytorch_func=pytorch_elementwise_ops,\n",
    "    tensorflow_func=tensorflow_elementwise_ops,\n",
    "    name=\"elementwise_operations\"\n",
    ")\n",
    "\n",
    "if ops_result['pytorch']['success'] and ops_result['tensorflow']['success']:\n",
    "    pt_results = ops_result['pytorch']['output']\n",
    "    tf_results = ops_result['tensorflow']['output']\n",
    "\n",
    "    print(\"Operation results comparison:\")\n",
    "    for op in pt_results.keys():\n",
    "        pt_val = pt_results[op]\n",
    "        tf_val = tf_results[op]\n",
    "        diff = abs(pt_val - tf_val)\n",
    "        print(f\"{op:15}: PyTorch={pt_val:.6f}, TensorFlow={tf_val:.6f}, diff={diff:.2e}\")\n",
    "\n",
    "# Show side-by-side activation functions\n",
    "pytorch_activations = \"\"\"\n",
    "import torch\n",
    "x = torch.randn(3, 4)\n",
    "\n",
    "# Activation functions\n",
    "relu = torch.relu(x)\n",
    "sigmoid = torch.sigmoid(x)\n",
    "tanh = torch.tanh(x)\n",
    "softmax = torch.softmax(x, dim=1)\n",
    "log_softmax = torch.log_softmax(x, dim=1)\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_activations = \"\"\"\n",
    "import tensorflow as tf\n",
    "x = tf.random.normal((3, 4))\n",
    "\n",
    "# Activation functions\n",
    "relu = tf.nn.relu(x)\n",
    "sigmoid = tf.nn.sigmoid(x)\n",
    "tanh = tf.nn.tanh(x)\n",
    "softmax = tf.nn.softmax(x, axis=1)\n",
    "log_softmax = tf.nn.log_softmax(x, axis=1)\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(pytorch_activations, tensorflow_activations, \"Activation Functions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction operations\n",
    "print(\"\\n2. Reduction Operations:\")\n",
    "\n",
    "def pytorch_reductions():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        x = torch.from_numpy(sample_data)\n",
    "\n",
    "        return {\n",
    "            'sum_all': torch.sum(x).item(),\n",
    "            'mean_all': torch.mean(x).item(),\n",
    "            'max_all': torch.max(x).item(),\n",
    "            'min_all': torch.min(x).item(),\n",
    "            'std_all': torch.std(x).item(),\n",
    "            'sum_axis0': torch.sum(x, dim=0).tolist(),\n",
    "            'mean_axis1': torch.mean(x, dim=1).tolist()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_reductions():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        x = tf.constant(sample_data)\n",
    "\n",
    "        return {\n",
    "            'sum_all': tf.reduce_sum(x).numpy().item(),\n",
    "            'mean_all': tf.reduce_mean(x).numpy().item(),\n",
    "            'max_all': tf.reduce_max(x).numpy().item(),\n",
    "            'min_all': tf.reduce_min(x).numpy().item(),\n",
    "            'std_all': tf.math.reduce_std(x).numpy().item(),\n",
    "            'sum_axis0': tf.reduce_sum(x, axis=0).numpy().tolist(),\n",
    "            'mean_axis1': tf.reduce_mean(x, axis=1).numpy().tolist()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "reductions_result = comparator.compare_implementations(\n",
    "    pytorch_func=pytorch_reductions,\n",
    "    tensorflow_func=tensorflow_reductions,\n",
    "    name=\"reduction_operations\"\n",
    ")\n",
    "\n",
    "if reductions_result['pytorch']['success'] and reductions_result['tensorflow']['success']:\n",
    "    pt_results = reductions_result['pytorch']['output']\n",
    "    tf_results = reductions_result['tensorflow']['output']\n",
    "\n",
    "    print(\"Reduction operations comparison:\")\n",
    "    for op in ['sum_all', 'mean_all', 'max_all', 'min_all', 'std_all']:\n",
    "        pt_val = pt_results[op]\n",
    "        tf_val = tf_results[op]\n",
    "        diff = abs(pt_val - tf_val)\n",
    "        print(f\"{op:12}: PyTorch={pt_val:.6f}, TensorFlow={tf_val:.6f}, diff={diff:.2e}\")\n",
    "\n",
    "# Show reduction operations side-by-side\n",
    "pytorch_reductions_code = \"\"\"\n",
    "import torch\n",
    "x = torch.randn(3, 4)\n",
    "\n",
    "# Global reductions\n",
    "total_sum = torch.sum(x)\n",
    "mean_val = torch.mean(x)\n",
    "max_val = torch.max(x)\n",
    "std_val = torch.std(x)\n",
    "\n",
    "# Axis-specific reductions\n",
    "sum_rows = torch.sum(x, dim=0)    # Sum along rows\n",
    "mean_cols = torch.mean(x, dim=1)  # Mean along columns\n",
    "\n",
    "# Keep dimensions\n",
    "sum_keepdim = torch.sum(x, dim=1, keepdim=True)\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_reductions_code = \"\"\"\n",
    "import tensorflow as tf\n",
    "x = tf.random.normal((3, 4))\n",
    "\n",
    "# Global reductions\n",
    "total_sum = tf.reduce_sum(x)\n",
    "mean_val = tf.reduce_mean(x)\n",
    "max_val = tf.reduce_max(x)\n",
    "std_val = tf.math.reduce_std(x)\n",
    "\n",
    "# Axis-specific reductions\n",
    "sum_rows = tf.reduce_sum(x, axis=0)    # Sum along rows\n",
    "mean_cols = tf.reduce_mean(x, axis=1)  # Mean along columns\n",
    "\n",
    "# Keep dimensions\n",
    "sum_keepdim = tf.reduce_sum(x, axis=1, keepdims=True)\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(pytorch_reductions_code, tensorflow_reductions_code, \"Reduction Operations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix Operations and Linear Algebra\n",
    "\n",
    "Comparing linear algebra operations essential for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MATRIX OPERATIONS AND LINEAR ALGEBRA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create matrices for linear algebra operations\n",
    "np.random.seed(42)\n",
    "matrix_a = np.random.randn(4, 3).astype(np.float32)\n",
    "matrix_b = np.random.randn(3, 5).astype(np.float32)\n",
    "square_matrix = np.random.randn(4, 4).astype(np.float32)\n",
    "\n",
    "print(f\"Matrix A shape: {matrix_a.shape}\")\n",
    "print(f\"Matrix B shape: {matrix_b.shape}\")\n",
    "print(f\"Square matrix shape: {square_matrix.shape}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"\\n1. Matrix Multiplication:\")\n",
    "\n",
    "def pytorch_matmul():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        A = torch.from_numpy(matrix_a)\n",
    "        B = torch.from_numpy(matrix_b)\n",
    "\n",
    "        # Different ways to do matrix multiplication\n",
    "        result1 = torch.matmul(A, B)\n",
    "        result2 = A @ B  # Python 3.5+ operator\n",
    "        result3 = torch.mm(A, B)  # 2D matrices only\n",
    "\n",
    "        # Batch matrix multiplication\n",
    "        batch_A = A.unsqueeze(0).repeat(2, 1, 1)  # Shape: (2, 4, 3)\n",
    "        batch_B = B.unsqueeze(0).repeat(2, 1, 1)  # Shape: (2, 3, 5)\n",
    "        batch_result = torch.bmm(batch_A, batch_B)  # Shape: (2, 4, 5)\n",
    "\n",
    "        return {\n",
    "            'matmul_result': result1,\n",
    "            'results_equal': torch.allclose(result1, result2) and torch.allclose(result1, result3),\n",
    "            'batch_shape': batch_result.shape\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_matmul():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        A = tf.constant(matrix_a)\n",
    "        B = tf.constant(matrix_b)\n",
    "\n",
    "        # Different ways to do matrix multiplication\n",
    "        result1 = tf.matmul(A, B)\n",
    "        result2 = A @ B  # Python 3.5+ operator\n",
    "        result3 = tf.linalg.matmul(A, B)\n",
    "\n",
    "        # Batch matrix multiplication\n",
    "        batch_A = tf.expand_dims(A, 0)\n",
    "        batch_A = tf.tile(batch_A, [2, 1, 1])  # Shape: (2, 4, 3)\n",
    "        batch_B = tf.expand_dims(B, 0)\n",
    "        batch_B = tf.tile(batch_B, [2, 1, 1])  # Shape: (2, 3, 5)\n",
    "        batch_result = tf.matmul(batch_A, batch_B)  # Shape: (2, 4, 5)\n",
    "\n",
    "        return {\n",
    "            'matmul_result': result1,\n",
    "            'results_equal': tf.reduce_all(tf.equal(result1, result2)) and tf.reduce_all(tf.equal(result1, result3)),\n",
    "            'batch_shape': batch_result.shape\n",
    "        }\n",
    "    return None\n",
    "\n",
    "matmul_result = comparator.compare_implementations(\n",
    "    pytorch_func=pytorch_matmul,\n",
    "    tensorflow_func=tensorflow_matmul,\n",
    "    name=\"matrix_multiplication\"\n",
    ")\n",
    "\n",
    "if matmul_result['pytorch']['success'] and matmul_result['tensorflow']['success']:\n",
    "    pt_results = matmul_result['pytorch']['output']\n",
    "    tf_results = matmul_result['tensorflow']['output']\n",
    "\n",
    "    print(f\"Matrix multiplication results match: {matmul_result['comparison']['outputs_equal']}\")\n",
    "    print(f\"PyTorch different methods equal: {pt_results['results_equal']}\")\n",
    "    print(f\"TensorFlow different methods equal: {tf_results['results_equal'].numpy()}\")\n",
    "    print(f\"Batch multiplication shapes - PyTorch: {pt_results['batch_shape']}, TensorFlow: {tf_results['batch_shape']}\")\n",
    "\n",
    "# Show matrix multiplication code comparison\n",
    "pytorch_matmul_code = \"\"\"\n",
    "import torch\n",
    "A = torch.randn(4, 3)\n",
    "B = torch.randn(3, 5)\n",
    "\n",
    "# Matrix multiplication methods\n",
    "result1 = torch.matmul(A, B)  # General\n",
    "result2 = A @ B               # Operator\n",
    "result3 = torch.mm(A, B)      # 2D only\n",
    "\n",
    "# Batch matrix multiplication\n",
    "batch_A = A.unsqueeze(0).repeat(2, 1, 1)\n",
    "batch_B = B.unsqueeze(0).repeat(2, 1, 1)\n",
    "batch_result = torch.bmm(batch_A, batch_B)\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_matmul_code = \"\"\"\n",
    "import tensorflow as tf\n",
    "A = tf.random.normal((4, 3))\n",
    "B = tf.random.normal((3, 5))\n",
    "\n",
    "# Matrix multiplication methods\n",
    "result1 = tf.matmul(A, B)         # General\n",
    "result2 = A @ B                   # Operator\n",
    "result3 = tf.linalg.matmul(A, B)  # Explicit\n",
    "\n",
    "# Batch matrix multiplication\n",
    "batch_A = tf.expand_dims(A, 0)\n",
    "batch_A = tf.tile(batch_A, [2, 1, 1])\n",
    "batch_B = tf.expand_dims(B, 0)\n",
    "batch_B = tf.tile(batch_B, [2, 1, 1])\n",
    "batch_result = tf.matmul(batch_A, batch_B)\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(pytorch_matmul_code, tensorflow_matmul_code, \"Matrix Multiplication\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced linear algebra operations\n",
    "print(\"\\n2. Advanced Linear Algebra:\")\n",
    "\n",
    "def pytorch_linalg():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        # Make square matrix symmetric for stable eigenvalues\n",
    "        A = torch.from_numpy(square_matrix)\n",
    "        A_sym = (A + A.T) / 2\n",
    "\n",
    "        # Linear algebra operations\n",
    "        det = torch.det(A_sym)\n",
    "        trace = torch.trace(A_sym)\n",
    "\n",
    "        # Eigenvalues and eigenvectors\n",
    "        eigenvals, eigenvecs = torch.linalg.eig(A_sym)\n",
    "        eigenvals = eigenvals.real  # Take real part\n",
    "\n",
    "        # SVD\n",
    "        U, S, Vh = torch.linalg.svd(A_sym)\n",
    "\n",
    "        # Matrix norms\n",
    "        frobenius_norm = torch.linalg.norm(A_sym, 'fro')\n",
    "        spectral_norm = torch.linalg.norm(A_sym, 2)\n",
    "\n",
    "        return {\n",
    "            'determinant': det.item(),\n",
    "            'trace': trace.item(),\n",
    "            'eigenvals_sum': torch.sum(eigenvals).item(),\n",
    "            'singular_vals_sum': torch.sum(S).item(),\n",
    "            'frobenius_norm': frobenius_norm.item(),\n",
    "            'spectral_norm': spectral_norm.item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_linalg():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        # Make square matrix symmetric for stable eigenvalues\n",
    "        A = tf.constant(square_matrix)\n",
    "        A_sym = (A + tf.transpose(A)) / 2\n",
    "\n",
    "        # Linear algebra operations\n",
    "        det = tf.linalg.det(A_sym)\n",
    "        trace = tf.linalg.trace(A_sym)\n",
    "\n",
    "        # Eigenvalues and eigenvectors\n",
    "        eigenvals, eigenvecs = tf.linalg.eig(A_sym)\n",
    "        eigenvals = tf.math.real(eigenvals)  # Take real part\n",
    "\n",
    "        # SVD\n",
    "        S, U, Vh = tf.linalg.svd(A_sym)\n",
    "\n",
    "        # Matrix norms\n",
    "        frobenius_norm = tf.linalg.norm(A_sym, 'fro')\n",
    "        spectral_norm = tf.linalg.norm(A_sym, 2)\n",
    "\n",
    "        return {\n",
    "            'determinant': det.numpy().item(),\n",
    "            'trace': trace.numpy().item(),\n",
    "            'eigenvals_sum': tf.reduce_sum(eigenvals).numpy().item(),\n",
    "            'singular_vals_sum': tf.reduce_sum(S).numpy().item(),\n",
    "            'frobenius_norm': frobenius_norm.numpy().item(),\n",
    "            'spectral_norm': spectral_norm.numpy().item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "linalg_result = comparator.compare_implementations(\n",
    "    pytorch_func=pytorch_linalg,\n",
    "    tensorflow_func=tensorflow_linalg,\n",
    "    name=\"linear_algebra\"\n",
    ")\n",
    "\n",
    "if linalg_result['pytorch']['success'] and linalg_result['tensorflow']['success']:\n",
    "    pt_results = linalg_result['pytorch']['output']\n",
    "    tf_results = linalg_result['tensorflow']['output']\n",
    "\n",
    "    print(\"Linear algebra operations comparison:\")\n",
    "    for op in pt_results.keys():\n",
    "        pt_val = pt_results[op]\n",
    "        tf_val = tf_results[op]\n",
    "        diff = abs(pt_val - tf_val)\n",
    "        print(f\"{op:18}: PyTorch={pt_val:.6f}, TensorFlow={tf_val:.6f}, diff={diff:.2e}\")\n",
    "\n",
    "# Linear algebra operations comparison table\n",
    "print(\"\\nüìã Linear Algebra Operations Comparison:\")\n",
    "linalg_ops = {\n",
    "    \"Matrix multiplication\": {\n",
    "        \"PyTorch\": \"torch.matmul(A, B) or A @ B\",\n",
    "        \"TensorFlow\": \"tf.matmul(A, B) or A @ B\"\n",
    "    },\n",
    "    \"Transpose\": {\n",
    "        \"PyTorch\": \"A.T or torch.transpose(A, 0, 1)\",\n",
    "        \"TensorFlow\": \"tf.transpose(A)\"\n",
    "    },\n",
    "    \"Determinant\": {\n",
    "        \"PyTorch\": \"torch.det(A)\",\n",
    "        \"TensorFlow\": \"tf.linalg.det(A)\"\n",
    "    },\n",
    "    \"Eigenvalues\": {\n",
    "        \"PyTorch\": \"torch.linalg.eig(A)\",\n",
    "        \"TensorFlow\": \"tf.linalg.eig(A)\"\n",
    "    },\n",
    "    \"SVD\": {\n",
    "        \"PyTorch\": \"torch.linalg.svd(A)\",\n",
    "        \"TensorFlow\": \"tf.linalg.svd(A)\"\n",
    "    },\n",
    "    \"Matrix inverse\": {\n",
    "        \"PyTorch\": \"torch.linalg.inv(A)\",\n",
    "        \"TensorFlow\": \"tf.linalg.inv(A)\"\n",
    "    },\n",
    "    \"Matrix norm\": {\n",
    "        \"PyTorch\": \"torch.linalg.norm(A, ord)\",\n",
    "        \"TensorFlow\": \"tf.linalg.norm(A, ord)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for op, frameworks in linalg_ops.items():\n",
    "    print(f\"{op:20} | PyTorch: {frameworks['PyTorch']:30} | TensorFlow: {frameworks['TensorFlow']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensor Reshaping and Manipulation\n",
    "\n",
    "Comparing tensor shape manipulation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TENSOR RESHAPING AND MANIPULATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample tensor for reshaping\n",
    "np.random.seed(42)\n",
    "sample_tensor_data = np.random.randn(2, 3, 4).astype(np.float32)\n",
    "\n",
    "print(f\"Original tensor shape: {sample_tensor_data.shape}\")\n",
    "\n",
    "def pytorch_reshaping():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        x = torch.from_numpy(sample_tensor_data)\n",
    "\n",
    "        # Reshaping operations\n",
    "        reshaped = x.reshape(6, 4)  # or x.view(6, 4)\n",
    "        flattened = x.flatten()  # or x.reshape(-1)\n",
    "\n",
    "        # Dimension manipulation\n",
    "        x.unsqueeze(0).squeeze(0)  # Add and remove dimension\n",
    "        transposed = x.transpose(0, 2)  # Swap dimensions 0 and 2\n",
    "        permuted = x.permute(2, 0, 1)  # Reorder all dimensions\n",
    "\n",
    "        # Concatenation and stacking\n",
    "        concat_dim0 = torch.cat([x, x], dim=0)  # Shape: (4, 3, 4)\n",
    "        stack_new_dim = torch.stack([x, x], dim=0)  # Shape: (2, 2, 3, 4)\n",
    "\n",
    "        # Splitting\n",
    "        split_tensors = torch.split(x, 1, dim=0)  # Split into tensors of size 1 along dim 0\n",
    "        chunk_tensors = torch.chunk(x, 2, dim=1)  # Split into 2 chunks along dim 1\n",
    "\n",
    "        return {\n",
    "            'reshaped_shape': reshaped.shape,\n",
    "            'flattened_shape': flattened.shape,\n",
    "            'transposed_shape': transposed.shape,\n",
    "            'permuted_shape': permuted.shape,\n",
    "            'concat_shape': concat_dim0.shape,\n",
    "            'stack_shape': stack_new_dim.shape,\n",
    "            'num_splits': len(split_tensors),\n",
    "            'num_chunks': len(chunk_tensors),\n",
    "            'chunk_shapes': [chunk.shape for chunk in chunk_tensors]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_reshaping():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        x = tf.constant(sample_tensor_data)\n",
    "\n",
    "        # Reshaping operations\n",
    "        reshaped = tf.reshape(x, (6, 4))\n",
    "        flattened = tf.reshape(x, (-1,))  # or tf.keras.layers.Flatten()(x)\n",
    "\n",
    "        # Dimension manipulation\n",
    "        tf.squeeze(tf.expand_dims(x, 0), 0)  # Add and remove dimension\n",
    "        transposed = tf.transpose(x, perm=[2, 1, 0])  # Reorder dimensions\n",
    "        permuted = tf.transpose(x, perm=[2, 0, 1])  # Reorder all dimensions\n",
    "\n",
    "        # Concatenation and stacking\n",
    "        concat_dim0 = tf.concat([x, x], axis=0)  # Shape: (4, 3, 4)\n",
    "        stack_new_dim = tf.stack([x, x], axis=0)  # Shape: (2, 2, 3, 4)\n",
    "\n",
    "        # Splitting\n",
    "        split_tensors = tf.split(x, num_or_size_splits=2, axis=0)  # Split into 2 parts along dim 0\n",
    "\n",
    "        return {\n",
    "            'reshaped_shape': reshaped.shape,\n",
    "            'flattened_shape': flattened.shape,\n",
    "            'transposed_shape': transposed.shape,\n",
    "            'permuted_shape': permuted.shape,\n",
    "            'concat_shape': concat_dim0.shape,\n",
    "            'stack_shape': stack_new_dim.shape,\n",
    "            'num_splits': len(split_tensors),\n",
    "            'split_shapes': [tensor.shape for tensor in split_tensors]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "reshaping_result = comparator.compare_implementations(\n",
    "    pytorch_func=pytorch_reshaping,\n",
    "    tensorflow_func=tensorflow_reshaping,\n",
    "    name=\"tensor_reshaping\"\n",
    ")\n",
    "\n",
    "if reshaping_result['pytorch']['success'] and reshaping_result['tensorflow']['success']:\n",
    "    pt_results = reshaping_result['pytorch']['output']\n",
    "    tf_results = reshaping_result['tensorflow']['output']\n",
    "\n",
    "    print(\"Tensor reshaping operations comparison:\")\n",
    "    print(f\"Reshaped shape - PyTorch: {pt_results['reshaped_shape']}, TensorFlow: {tf_results['reshaped_shape']}\")\n",
    "    print(f\"Flattened shape - PyTorch: {pt_results['flattened_shape']}, TensorFlow: {tf_results['flattened_shape']}\")\n",
    "    print(f\"Transposed shape - PyTorch: {pt_results['transposed_shape']}, TensorFlow: {tf_results['transposed_shape']}\")\n",
    "    print(f\"Permuted shape - PyTorch: {pt_results['permuted_shape']}, TensorFlow: {tf_results['permuted_shape']}\")\n",
    "    print(f\"Concatenated shape - PyTorch: {pt_results['concat_shape']}, TensorFlow: {tf_results['concat_shape']}\")\n",
    "    print(f\"Stacked shape - PyTorch: {pt_results['stack_shape']}, TensorFlow: {tf_results['stack_shape']}\")\n",
    "\n",
    "# Show reshaping operations side-by-side\n",
    "pytorch_reshape_code = \"\"\"\n",
    "import torch\n",
    "x = torch.randn(2, 3, 4)\n",
    "\n",
    "# Reshaping\n",
    "reshaped = x.reshape(6, 4)  # or x.view(6, 4)\n",
    "flattened = x.flatten()     # or x.reshape(-1)\n",
    "\n",
    "# Dimension manipulation\n",
    "unsqueezed = x.unsqueeze(0)      # Add dimension\n",
    "squeezed = unsqueezed.squeeze(0)  # Remove dimension\n",
    "transposed = x.transpose(0, 2)    # Swap dims\n",
    "permuted = x.permute(2, 0, 1)     # Reorder dims\n",
    "\n",
    "# Concatenation and stacking\n",
    "concat = torch.cat([x, x], dim=0)\n",
    "stack = torch.stack([x, x], dim=0)\n",
    "\"\"\"\n",
    "\n",
    "tensorflow_reshape_code = \"\"\"\n",
    "import tensorflow as tf\n",
    "x = tf.random.normal((2, 3, 4))\n",
    "\n",
    "# Reshaping\n",
    "reshaped = tf.reshape(x, (6, 4))\n",
    "flattened = tf.reshape(x, (-1,))\n",
    "\n",
    "# Dimension manipulation\n",
    "expanded = tf.expand_dims(x, 0)      # Add dimension\n",
    "squeezed = tf.squeeze(expanded, 0)   # Remove dimension\n",
    "transposed = tf.transpose(x, [2, 1, 0])  # Reorder dims\n",
    "permuted = tf.transpose(x, [2, 0, 1])    # Reorder dims\n",
    "\n",
    "# Concatenation and stacking\n",
    "concat = tf.concat([x, x], axis=0)\n",
    "stack = tf.stack([x, x], axis=0)\n",
    "\"\"\"\n",
    "\n",
    "print(create_side_by_side_comparison(pytorch_reshape_code, tensorflow_reshape_code, \"Tensor Reshaping\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Benchmarking\n",
    "\n",
    "Comparing the performance of tensor operations between frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE BENCHMARKING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create larger tensors for meaningful benchmarks\n",
    "large_size = (1000, 1000)\n",
    "np.random.seed(42)\n",
    "large_data_a = np.random.randn(*large_size).astype(np.float32)\n",
    "large_data_b = np.random.randn(*large_size).astype(np.float32)\n",
    "\n",
    "print(f\"Benchmarking with tensors of shape: {large_size}\")\n",
    "print(f\"Memory per tensor: {large_data_a.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Benchmark matrix multiplication\n",
    "def pytorch_matmul_benchmark():\n",
    "    if PYTORCH_AVAILABLE:\n",
    "        A = torch.from_numpy(large_data_a)\n",
    "        B = torch.from_numpy(large_data_b)\n",
    "\n",
    "        # Warm up\n",
    "        for _ in range(3):\n",
    "            _ = torch.matmul(A, B)\n",
    "\n",
    "        # Actual benchmark\n",
    "        start_time = time.time()\n",
    "        result = torch.matmul(A, B)\n",
    "        end_time = time.time()\n",
    "\n",
    "        return {\n",
    "            'execution_time': end_time - start_time,\n",
    "            'result_shape': result.shape,\n",
    "            'result_mean': torch.mean(result).item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def tensorflow_matmul_benchmark():\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        A = tf.constant(large_data_a)\n",
    "        B = tf.constant(large_data_b)\n",
    "\n",
    "        # Warm up\n",
    "        for _ in range(3):\n",
    "            _ = tf.matmul(A, B)\n",
    "\n",
    "        # Actual benchmark\n",
    "        start_time = time.time()\n",
    "        result = tf.matmul(A, B)\n",
    "        end_time = time.time()\n",
    "\n",
    "        return {\n",
    "            'execution_time': end_time - start_time,\n",
    "            'result_shape': result.shape,\n",
    "            'result_mean': tf.reduce_mean(result).numpy().item()\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_result = comparator.benchmark_performance(\n",
    "    pytorch_func=pytorch_matmul_benchmark,\n",
    "    tensorflow_func=tensorflow_matmul_benchmark,\n",
    "    num_runs=5,\n",
    "    warmup_runs=2\n",
    ")\n",
    "\n",
    "print(\"\\nMatrix Multiplication Benchmark Results:\")\n",
    "if benchmark_result['pytorch'].get('success'):\n",
    "    pt_time = benchmark_result['pytorch']['mean_time']\n",
    "    print(f\"PyTorch: {pt_time:.4f}s (¬±{benchmark_result['pytorch']['std_time']:.4f}s)\")\n",
    "\n",
    "if benchmark_result['tensorflow'].get('success'):\n",
    "    tf_time = benchmark_result['tensorflow']['mean_time']\n",
    "    print(f\"TensorFlow: {tf_time:.4f}s (¬±{benchmark_result['tensorflow']['std_time']:.4f}s)\")\n",
    "\n",
    "if 'relative_performance' in benchmark_result:\n",
    "    rel_perf = benchmark_result['relative_performance']\n",
    "    faster_framework = rel_perf['faster_framework']\n",
    "    speedup = rel_perf['speedup_ratio']\n",
    "    print(f\"\\nüèÜ {faster_framework.capitalize()} is {speedup:.2f}x faster\")\n",
    "\n",
    "# Visualize benchmark results if we have data\n",
    "if benchmark_result['pytorch'].get('success') or benchmark_result['tensorflow'].get('success'):\n",
    "    visualizer = FrameworkVisualizer()\n",
    "    fig = visualizer.plot_performance_comparison(\n",
    "        benchmark_result,\n",
    "        title=\"Matrix Multiplication Performance\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "**What we've learned:**\n",
    "\n",
    "1. **Tensor Creation**: Both frameworks offer similar tensor creation methods with slight API differences\n",
    "2. **Basic Operations**: Element-wise and reduction operations are nearly identical in functionality\n",
    "3. **Linear Algebra**: Both provide comprehensive linear algebra operations with similar performance\n",
    "4. **Reshaping**: Tensor manipulation operations exist in both, with different naming conventions\n",
    "5. **Performance**: Performance differences are often minimal and depend on specific operations and hardware\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "| Aspect | PyTorch | TensorFlow |\n",
    "|--------|---------|------------|\n",
    "| **Tensor Creation** | `torch.tensor()`, `torch.zeros()` | `tf.constant()`, `tf.zeros()` |\n",
    "| **Reshaping** | `.reshape()`, `.view()` | `tf.reshape()` |\n",
    "| **Dimension Ops** | `.unsqueeze()`, `.squeeze()` | `tf.expand_dims()`, `tf.squeeze()` |\n",
    "| **Reductions** | `torch.sum()`, `torch.mean()` | `tf.reduce_sum()`, `tf.reduce_mean()` |\n",
    "| **Axis Parameter** | `dim=` | `axis=` |\n",
    "| **Transpose** | `.T`, `.transpose()` | `tf.transpose()` |\n",
    "| **Random Ops** | `torch.randn()`, `torch.rand()` | `tf.random.normal()`, `tf.random.uniform()` |\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "**PyTorch:**\n",
    "- Use `.view()` when you're sure about memory layout, `.reshape()` otherwise\n",
    "- Prefer `torch.matmul()` or `@` operator for matrix multiplication\n",
    "- Use `.item()` to extract scalar values from tensors\n",
    "- Leverage broadcasting for efficient operations\n",
    "\n",
    "**TensorFlow:**\n",
    "- Use `tf.reshape()` for all reshaping operations\n",
    "- Prefer `tf.matmul()` or `@` operator for matrix multiplication\n",
    "- Use `.numpy()` to convert to NumPy when needed\n",
    "- Remember that TensorFlow operations return new tensors (immutable)\n",
    "\n",
    "**Performance Considerations:**\n",
    "- Both frameworks are highly optimized for tensor operations\n",
    "- Performance differences are usually small for basic operations\n",
    "- GPU acceleration provides similar benefits in both frameworks\n",
    "- Choose based on ecosystem and development preferences, not just raw performance\n",
    "\n",
    "**When to Choose What:**\n",
    "- **PyTorch**: Research, prototyping, dynamic models, easier debugging\n",
    "- **TensorFlow**: Production deployment, mobile/edge devices, large-scale serving\n",
    "\n",
    "**Next Steps:**\n",
    "- Learn about computational graphs and automatic differentiation\n",
    "- Explore GPU acceleration and device management\n",
    "- Understand framework-specific optimization techniques\n",
    "- Practice building neural network layers using these tensor operations\n",
    "\n",
    "Both frameworks provide powerful tensor operations with similar capabilities. The choice often comes down to ecosystem preferences, deployment requirements, and team expertise rather than fundamental differences in tensor operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
